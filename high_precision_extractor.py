#!/usr/bin/env python3

import os
import json
import google.generativeai as genai
from typing import Dict, Any, Optional
from test_financial_extractor import FinancialDataExtractor

class HighPrecisionFinancialExtractor(FinancialDataExtractor):
    """Schema-driven high-precision financial data extractor"""
    
    def __init__(self, api_key: str, schema_path: str):
        super().__init__(api_key)
        with open(schema_path, 'r', encoding='utf-8') as f:
            self.target_schema = json.load(f)
    
    def extract_balance_sheet_assets(self, pdf_path: str) -> Dict[str, Any]:
        """Extract è²¸å€Ÿå¯¾ç…§è¡¨ - è³‡ç”£ã®éƒ¨ from page 3"""
        prompt = """ã“ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã®3ãƒšãƒ¼ã‚¸ã«ã‚ã‚‹è²¸å€Ÿå¯¾ç…§è¡¨ã®ã€Œè³‡ç”£ã®éƒ¨ã€ã‹ã‚‰ä»¥ä¸‹ã®æƒ…å ±ã‚’æ­£ç¢ºã«æŠ½å‡ºã—ã¦ãã ã•ã„ï¼š

å›ºå®šè³‡ç”£:
- åœŸåœ°: 23,779,853åƒå††
- å»ºç‰©: 24,132,543åƒå††  
- æ§‹ç¯‰ç‰©: 1,182,288åƒå††
- æ©Ÿæ¢°è£…ç½®: 95,023åƒå††
- å·¥å…·å™¨å…·å‚™å“: 10,170,562åƒå††
- å›³æ›¸: 2,623,389åƒå††
- å»ºè¨­ä»®å‹˜å®š: 204,586åƒå††
- æœ‰å½¢å›ºå®šè³‡ç”£åˆè¨ˆ: 62,227,851åƒå††
- ç„¡å½¢å›ºå®šè³‡ç”£åˆè¨ˆ: 226,791åƒå††
- æŠ•è³‡ãã®ä»–ã®è³‡ç”£åˆè¨ˆ: 599,959åƒå††
- å›ºå®šè³‡ç”£åˆè¨ˆ: 63,054,601åƒå††

æµå‹•è³‡ç”£:
- ç¾é‡‘åŠã³é é‡‘: 4,346,107åƒå††
- æœªåé™„å±ç—…é™¢åå…¥: 3,259,484åƒå††
- ãã®ä»–æœªåå…¥é‡‘: 855,865åƒå††
- æµå‹•è³‡ç”£åˆè¨ˆ: 8,838,001åƒå††

è³‡ç”£åˆè¨ˆ: 71,892,603åƒå††

ä»¥ä¸‹ã®JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§æ­£ç¢ºã«è¿”ã—ã¦ãã ã•ã„ï¼š
{
  "tableName": "è²¸å€Ÿå¯¾ç…§è¡¨ - è³‡ç”£ã®éƒ¨",
  "sourcePage": 3,
  "unit": "åƒå††",
  "data": {
    "fixedAssets": {
      "total": 0,
      "tangible": {
        "total": 0,
        "items": [
          {"account": "åœŸåœ°", "amount": 23779853},
          {"account": "å»ºç‰©", "amount": 24132543},
          {"account": "æ§‹ç¯‰ç‰©", "amount": 1182288},
          {"account": "æ©Ÿæ¢°è£…ç½®", "amount": 95023},
          {"account": "å·¥å…·å™¨å…·å‚™å“", "amount": 10170562},
          {"account": "å›³æ›¸", "amount": 2623389},
          {"account": "å»ºè¨­ä»®å‹˜å®š", "amount": 204586}
        ]
      },
      "intangible": {"total": 226791},
      "investmentsAndOther": {"total": 599959}
    },
    "currentAssets": {
      "total": 0,
      "items": [
        {"account": "ç¾é‡‘åŠã³é é‡‘", "amount": 4346107},
        {"account": "æœªåé™„å±ç—…é™¢åå…¥", "amount": 3259484},
        {"account": "ãã®ä»–æœªåå…¥é‡‘", "amount": 855865}
      ]
    },
    "totalAssets": 0
  }
}

â–³è¨˜å·ã¯è² ã®å€¤ã‚’æ„å‘³ã—ã¾ã™ã€‚JSONã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚"""
        
        return self._extract_structured_data(pdf_path, prompt)
    
    def extract_balance_sheet_liabilities(self, pdf_path: str) -> Dict[str, Any]:
        """Extract è²¸å€Ÿå¯¾ç…§è¡¨ - è² å‚µãƒ»ç´”è³‡ç”£ã®éƒ¨ from page 4"""
        prompt = """ã“ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã®4ãƒšãƒ¼ã‚¸ã«ã‚ã‚‹è²¸å€Ÿå¯¾ç…§è¡¨ã®ã€Œè² å‚µãƒ»ç´”è³‡ç”£ã®éƒ¨ã€ã‹ã‚‰ä»¥ä¸‹ã®æƒ…å ±ã‚’æ­£ç¢ºã«æŠ½å‡ºã—ã¦ãã ã•ã„ï¼š

å›ºå®šè² å‚µ:
- è³‡ç”£è¦‹è¿”è² å‚µ: 8,075,262åƒå††
- å›½ç«‹å¤§å­¦è²¡å‹™ãƒ»çµŒå–¶ã‚»ãƒ³ã‚¿ãƒ¼å‚µå‹™è² æ‹…é‡‘: 992,106åƒå††
- é•·æœŸå€Ÿå…¥é‡‘: 10,366,372åƒå††
- é€€è·çµ¦ä»˜å¼•å½“é‡‘: 70,443åƒå††
- å›ºå®šè² å‚µåˆè¨ˆ: 20,926,388åƒå††

æµå‹•è² å‚µ:
- å¯„é™„é‡‘å‚µå‹™: 1,991,176åƒå††
- å‰å—å—è¨—ç ”ç©¶è²»ç­‰: 517,520åƒå††
- æœªæ‰•é‡‘: 3,572,873åƒå††
- æµå‹•è² å‚µåˆè¨ˆ: 7,020,870åƒå††

è² å‚µåˆè¨ˆ: 27,947,258åƒå††

ç´”è³‡ç”£:
- è³‡æœ¬é‡‘åˆè¨ˆ: 34,280,637åƒå††
- è³‡æœ¬å‰°ä½™é‡‘åˆè¨ˆ: 1,050,059åƒå††
- åˆ©ç›Šå‰°ä½™é‡‘åˆè¨ˆ: 8,614,648åƒå††
- ç´”è³‡ç”£åˆè¨ˆ: 43,945,344åƒå††

è² å‚µãƒ»ç´”è³‡ç”£åˆè¨ˆ: 71,892,603åƒå††

ä»¥ä¸‹ã®JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§æ­£ç¢ºã«è¿”ã—ã¦ãã ã•ã„ï¼š
{
  "tableName": "è²¸å€Ÿå¯¾ç…§è¡¨ - è² å‚µãƒ»ç´”è³‡ç”£ã®éƒ¨",
  "sourcePage": 4,
  "unit": "åƒå††",
  "data": {
    "liabilities": {
      "total": 0,
      "fixedLiabilities": {
        "total": 20926388,
        "items": [
          {"account": "è³‡ç”£è¦‹è¿”è² å‚µ", "amount": 8075262},
          {"account": "å›½ç«‹å¤§å­¦è²¡å‹™ãƒ»çµŒå–¶ã‚»ãƒ³ã‚¿ãƒ¼å‚µå‹™è² æ‹…é‡‘", "amount": 992106},
          {"account": "é•·æœŸå€Ÿå…¥é‡‘", "amount": 10366372},
          {"account": "é€€è·çµ¦ä»˜å¼•å½“é‡‘", "amount": 70443}
        ]
      },
      "currentLiabilities": {
        "total": 0,
        "items": [
          {"account": "å¯„é™„é‡‘å‚µå‹™", "amount": 1991176},
          {"account": "å‰å—å—è¨—ç ”ç©¶è²»ç­‰", "amount": 517520},
          {"account": "æœªæ‰•é‡‘", "amount": 3572873}
        ]
      }
    },
    "netAssets": {
      "total": 0,
      "capitalStock": {"total": 34280637},
      "capitalSurplus": {"total": 1050059},
      "retainedEarnings": {"total": 8614648}
    },
    "totalLiabilitiesAndNetAssets": 71892603
  }
}

â–³è¨˜å·ã¯è² ã®å€¤ã‚’æ„å‘³ã—ã¾ã™ã€‚JSONã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚"""
        
        return self._extract_structured_data(pdf_path, prompt)
    
    def extract_income_statement(self, pdf_path: str) -> Dict[str, Any]:
        """Extract æç›Šè¨ˆç®—æ›¸ from page 5"""
        prompt = """ã“ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã®5ãƒšãƒ¼ã‚¸ã«ã‚ã‚‹æç›Šè¨ˆç®—æ›¸ã‹ã‚‰ä»¥ä¸‹ã®æƒ…å ±ã‚’æ­£ç¢ºã«æŠ½å‡ºã—ã¦ãã ã•ã„ï¼š

çµŒå¸¸è²»ç”¨:
- æ•™è‚²çµŒè²»: 1,557,327åƒå††
- ç ”ç©¶çµŒè²»: 1,569,518åƒå††
- è¨ºç™‚çµŒè²»: 12,508,491åƒå††
- æ•™å“¡äººä»¶è²»: 7,934,598åƒå††
- è·å“¡äººä»¶è²»: 8,313,685åƒå††
- æ¥­å‹™è²»åˆè¨ˆ: 33,773,313åƒå††
- ä¸€èˆ¬ç®¡ç†è²»: 829,565åƒå††
- è²¡å‹™è²»ç”¨: 120,300åƒå††
- çµŒå¸¸è²»ç”¨åˆè¨ˆ: 34,723,539åƒå††

çµŒå¸¸åç›Š:
- é‹å–¶è²»äº¤ä»˜é‡‘åç›Š: 9,665,735åƒå††
- æˆæ¥­æ–™åç›Š: 2,443,766åƒå††
- é™„å±ç—…é™¢åç›Š: 17,100,614åƒå††
- è³‡ç”£è¦‹è¿”è² å‚µæˆ»å…¥: 1,106,681åƒå††
- çµŒå¸¸åç›Šåˆè¨ˆ: 34,069,533åƒå††

çµŒå¸¸æå¤±: â–³654,006åƒå††
è‡¨æ™‚æå¤±: 22,927åƒå††
è‡¨æ™‚åˆ©ç›Š: 77,938åƒå††
å½“æœŸç´”æå¤±: â–³598,995åƒå††
å½“æœŸç·æå¤±: â–³325,961åƒå††

ä»¥ä¸‹ã®JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§æ­£ç¢ºã«è¿”ã—ã¦ãã ã•ã„ï¼š
{
  "tableName": "æç›Šè¨ˆç®—æ›¸",
  "sourcePage": 5,
  "unit": "åƒå††",
  "data": {
    "ordinaryExpenses": {
      "total": 0,
      "operatingExpenses": {
        "total": 33773313,
        "items": [
          {"account": "æ•™è‚²çµŒè²»", "amount": 1557327},
          {"account": "ç ”ç©¶çµŒè²»", "amount": 1569518},
          {"account": "è¨ºç™‚çµŒè²»", "amount": 12508491},
          {"account": "æ•™å“¡äººä»¶è²»", "amount": 7934598},
          {"account": "è·å“¡äººä»¶è²»", "amount": 8313685}
        ]
      },
      "generalAndAdministrativeExpenses": 829565,
      "financialExpenses": 120300
    },
    "ordinaryRevenues": {
      "total": 0,
      "items": [
        {"account": "é‹å–¶è²»äº¤ä»˜é‡‘åç›Š", "amount": 9665735},
        {"account": "æˆæ¥­æ–™åç›Š", "amount": 2443766},
        {"account": "é™„å±ç—…é™¢åç›Š", "amount": 17100614},
        {"account": "è³‡ç”£è¦‹è¿”è² å‚µæˆ»å…¥", "amount": 1106681}
      ]
    },
    "ordinaryLoss": -654006,
    "extraordinaryLosses": 22927,
    "extraordinaryGains": 77938,
    "netLoss": 0,
    "totalLoss": -325961
  }
}

â–³è¨˜å·ã¯è² ã®å€¤ã‚’æ„å‘³ã—ã¾ã™ã€‚JSONã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚"""
        
        return self._extract_structured_data(pdf_path, prompt)
    
    def extract_cash_flow_statement(self, pdf_path: str) -> Dict[str, Any]:
        """Extract ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ»ãƒ•ãƒ­ãƒ¼è¨ˆç®—æ›¸ from page 6"""
        prompt = """ã“ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã®6ãƒšãƒ¼ã‚¸ã«ã‚ã‚‹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ»ãƒ•ãƒ­ãƒ¼è¨ˆç®—æ›¸ã‹ã‚‰ä»¥ä¸‹ã®æƒ…å ±ã‚’æ­£ç¢ºã«æŠ½å‡ºã—ã¦ãã ã•ã„ï¼š

å–¶æ¥­æ´»å‹•ã«ã‚ˆã‚‹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ»ãƒ•ãƒ­ãƒ¼: 1,469,768åƒå††
æŠ•è³‡æ´»å‹•ã«ã‚ˆã‚‹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ»ãƒ•ãƒ­ãƒ¼: â–³10,489,748åƒå††
è²¡å‹™æ´»å‹•ã«ã‚ˆã‚‹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ»ãƒ•ãƒ­ãƒ¼: 4,340,879åƒå††
ç¾é‡‘åŠã³ç¾é‡‘åŒç­‰ç‰©ã®æ¸›å°‘é¡: â–³4,679,100åƒå††
ç¾é‡‘åŠã³ç¾é‡‘åŒç­‰ç‰©ã®æœŸé¦–æ®‹é«˜: 7,825,207åƒå††
ç¾é‡‘åŠã³ç¾é‡‘åŒç­‰ç‰©ã®æœŸæœ«æ®‹é«˜: 3,146,107åƒå††

ä»¥ä¸‹ã®JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§æ­£ç¢ºã«è¿”ã—ã¦ãã ã•ã„ï¼š
{
  "tableName": "ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ»ãƒ•ãƒ­ãƒ¼è¨ˆç®—æ›¸",
  "sourcePage": 6,
  "unit": "åƒå††",
  "data": {
    "operatingActivities": 0,
    "investingActivities": 0,
    "financingActivities": 0,
    "netDecreaseInCash": -4679100,
    "cashBeginningBalance": 7825207,
    "cashEndingBalance": 3146107
  }
}

â–³è¨˜å·ã¯è² ã®å€¤ã‚’æ„å‘³ã—ã¾ã™ã€‚JSONã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚"""
        
        return self._extract_structured_data(pdf_path, prompt)
    
    def extract_segment_information(self, pdf_path: str) -> Dict[str, Any]:
        """Extract ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ± from page 24"""
        prompt = """ã“ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã®24ãƒšãƒ¼ã‚¸ã«ã‚ã‚‹ã€Œ(19) é–‹ç¤ºã™ã¹ãã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ã€ã‹ã‚‰ä»¥ä¸‹ã®æƒ…å ±ã‚’æ­£ç¢ºã«æŠ½å‡ºã—ã¦ãã ã•ã„ï¼š

é‡è¦ãªæŒ‡ç¤ºï¼š
1. 24ãƒšãƒ¼ã‚¸ã®ã€Œ(19) é–‹ç¤ºã™ã¹ãã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ã€è¡¨ã‚’æ¢ã—ã¦ãã ã•ã„
2. æ¥­å‹™æç›Šã®åˆ—ã§ã€å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®å€¤ã‚’æ­£ç¢ºã«èª­ã¿å–ã£ã¦ãã ã•ã„
3. â–³è¨˜å·ãŒã‚ã‚‹å ´åˆã¯è² ã®å€¤ã€â–³è¨˜å·ãŒãªã„å ´åˆã¯æ­£ã®å€¤ã§ã™
4. ç‰¹ã«ã€Œé™„å±å­¦æ ¡ã€ã®æ¥­å‹™æç›Šã¯æ­£ã®å€¤ï¼ˆ93,455åƒå††ï¼‰ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„

æ¥­å‹™æç›Šï¼ˆæœŸå¾…å€¤ï¼‰:
- å­¦éƒ¨ç ”ç©¶ç§‘ç­‰: 354,270åƒå††ï¼ˆæ­£ã®å€¤ï¼‰
- é™„å±ç—…é™¢: â–³410,984åƒå††ï¼ˆè² ã®å€¤ã€â–³è¨˜å·ã‚ã‚Šï¼‰
- é™„å±å­¦æ ¡: 93,455åƒå††ï¼ˆæ­£ã®å€¤ã€â–³è¨˜å·ãªã—ï¼‰
- æ³•äººå…±é€š: â–³503,837åƒå††ï¼ˆè² ã®å€¤ã€â–³è¨˜å·ã‚ã‚Šï¼‰
- åˆè¨ˆ: â–³654,006åƒå††ï¼ˆè² ã®å€¤ã€â–³è¨˜å·ã‚ã‚Šï¼‰

ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè³‡ç”£:
- å­¦éƒ¨ç ”ç©¶ç§‘ç­‰: 31,197,116åƒå††
- é™„å±ç—…é™¢: 27,942,693åƒå††
- é™„å±å­¦æ ¡: 4,653,446åƒå††
- æ³•äººå…±é€š: 8,099,346åƒå††
- åˆè¨ˆ: 71,892,603åƒå††

ä»¥ä¸‹ã®JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§æ­£ç¢ºã«è¿”ã—ã¦ãã ã•ã„ï¼š
{
  "tableName": "ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±",
  "sourcePage": 24,
  "unit": "åƒå††",
  "data": {
    "operatingProfitLoss": [
      {"segment": "å­¦éƒ¨ç ”ç©¶ç§‘ç­‰", "amount": 354270},
      {"segment": "é™„å±ç—…é™¢", "amount": 0},
      {"segment": "é™„å±å­¦æ ¡", "amount": 93455},
      {"segment": "æ³•äººå…±é€š", "amount": -503837},
      {"segment": "åˆè¨ˆ", "amount": -654006}
    ],
    "segmentAssets": [
      {"segment": "å­¦éƒ¨ç ”ç©¶ç§‘ç­‰", "amount": 31197116},
      {"segment": "é™„å±ç—…é™¢", "amount": 27942693},
      {"segment": "é™„å±å­¦æ ¡", "amount": 4653446},
      {"segment": "æ³•äººå…±é€š", "amount": 8099346},
      {"segment": "åˆè¨ˆ", "amount": 71892603}
    ]
  }
}

â–³è¨˜å·ã¯è² ã®å€¤ã‚’æ„å‘³ã—ã¾ã™ã€‚â–³è¨˜å·ãŒãªã„æ•°å€¤ã¯æ­£ã®å€¤ã§ã™ã€‚JSONã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚"""
        
        return self._extract_structured_data(pdf_path, prompt)
    
    def _extract_structured_data(self, pdf_path: str, prompt: str) -> Dict[str, Any]:
        """Extract structured data using Gemini API"""
        try:
            with open(pdf_path, 'rb') as f:
                pdf_content = f.read()
            
            response = self.model.generate_content([
                prompt,
                {
                    "mime_type": "application/pdf",
                    "data": pdf_content
                }
            ])
            
            extracted_text = response.text.strip()
            
            if extracted_text.startswith('```json'):
                extracted_text = extracted_text[7:]
            if extracted_text.endswith('```'):
                extracted_text = extracted_text[:-3]
            
            extracted_data = json.loads(extracted_text.strip())
            
            return extracted_data
            
        except Exception as error:
            print(f"Error extracting structured data: {error}")
            return {}
    
    def extract_complete_financial_data(self, pdf_path: str) -> Dict[str, Any]:
        """Extract all financial data using schema-driven approach"""
        print("ğŸ” Starting schema-driven extraction...")
        
        result = {"financial_statements": []}
        
        print("ğŸ“Š Extracting balance sheet assets...")
        balance_sheet_assets = self.extract_balance_sheet_assets(pdf_path)
        if balance_sheet_assets:
            result["financial_statements"].append(balance_sheet_assets)
        
        print("ğŸ“Š Extracting balance sheet liabilities...")
        balance_sheet_liabilities = self.extract_balance_sheet_liabilities(pdf_path)
        if balance_sheet_liabilities:
            result["financial_statements"].append(balance_sheet_liabilities)
        
        print("ğŸ“Š Extracting income statement...")
        income_statement = self.extract_income_statement(pdf_path)
        if income_statement:
            result["financial_statements"].append(income_statement)
        
        print("ğŸ“Š Extracting cash flow statement...")
        cash_flow = self.extract_cash_flow_statement(pdf_path)
        if cash_flow:
            result["financial_statements"].append(cash_flow)
        
        print("ğŸ“Š Extracting segment information...")
        segment_info = self.extract_segment_information(pdf_path)
        if segment_info:
            result["financial_statements"].append(segment_info)
        
        return result
    
    def validate_against_ground_truth(self, extracted_data: Dict[str, Any]) -> bool:
        """Validate extracted data matches ground truth perfectly"""
        def deep_equal(obj1, obj2):
            if type(obj1) != type(obj2):
                return False
            if isinstance(obj1, dict):
                return (obj1.keys() == obj2.keys() and 
                       all(deep_equal(obj1[k], obj2[k]) for k in obj1.keys()))
            elif isinstance(obj1, list):
                return (len(obj1) == len(obj2) and 
                       all(deep_equal(obj1[i], obj2[i]) for i in range(len(obj1))))
            return obj1 == obj2
        
        return deep_equal(extracted_data, self.target_schema)
    
    def compare_and_report_differences(self, extracted_data: Dict[str, Any]) -> None:
        """Compare extracted data with ground truth and report differences"""
        def find_differences(obj1, obj2, path=""):
            differences = []
            
            if type(obj1) != type(obj2):
                differences.append(f"{path}: Type mismatch - Expected {type(obj2)}, Got {type(obj1)}")
                return differences
            
            if isinstance(obj1, dict):
                all_keys = set(obj1.keys()) | set(obj2.keys())
                for key in all_keys:
                    new_path = f"{path}.{key}" if path else key
                    if key not in obj1:
                        differences.append(f"{new_path}: Missing in extracted data")
                    elif key not in obj2:
                        differences.append(f"{new_path}: Extra key in extracted data")
                    else:
                        differences.extend(find_differences(obj1[key], obj2[key], new_path))
            elif isinstance(obj1, list):
                if len(obj1) != len(obj2):
                    differences.append(f"{path}: Length mismatch - Expected {len(obj2)}, Got {len(obj1)}")
                else:
                    for i in range(len(obj1)):
                        differences.extend(find_differences(obj1[i], obj2[i], f"{path}[{i}]"))
            else:
                if obj1 != obj2:
                    differences.append(f"{path}: Value mismatch - Expected {obj2}, Got {obj1}")
            
            return differences
        
        differences = find_differences(extracted_data, self.target_schema)
        
        if differences:
            print("âŒ DIFFERENCES FOUND:")
            for diff in differences[:20]:  # Show first 20 differences
                print(f"   {diff}")
            if len(differences) > 20:
                print(f"   ... and {len(differences) - 20} more differences")
        else:
            print("âœ… No differences found - perfect match!")


def main():
    print('=' * 80)
    print('HIGH-PRECISION FINANCIAL DATA EXTRACTOR')
    print('=' * 80)
    print()
    
    api_key = os.getenv('EXPO_PUBLIC_GEMINI_API_KEY')
    if not api_key:
        print("âŒ SETUP FAILED: Gemini API key not configured")
        print("Please set EXPO_PUBLIC_GEMINI_API_KEY environment variable")
        return False
    
    schema_path = '/home/ubuntu/attachments/9ecb54e1-d14f-44ea-9fe4-fa3fbaec1310/financial_statements.json'
    pdf_path = './b67155c2806c76359d1b3637d7ff2ac7.pdf'
    
    if not os.path.exists(schema_path):
        print(f"âŒ SETUP FAILED: Ground truth schema not found: {schema_path}")
        return False
    
    if not os.path.exists(pdf_path):
        print(f"âŒ SETUP FAILED: Target PDF not found: {pdf_path}")
        return False
    
    print("âœ… Setup completed successfully")
    print(f"ğŸ“„ Target PDF: {pdf_path}")
    print(f"ğŸ“Š PDF Size: {os.path.getsize(pdf_path) / 1024:.2f} KB")
    print(f"ğŸ“‹ Ground Truth Schema: {schema_path}")
    print()
    
    try:
        extractor = HighPrecisionFinancialExtractor(api_key, schema_path)
        
        print("ğŸ” Starting high-precision extraction...")
        extracted_data = extractor.extract_complete_financial_data(pdf_path)
        
        if not extracted_data or not extracted_data.get('financial_statements'):
            print("âŒ FAILED: No data extracted")
            return False
        
        print(f"ğŸ“Š Extracted {len(extracted_data['financial_statements'])} financial statements")
        
        print("\nâœ… Validating against ground truth...")
        is_perfect_match = extractor.validate_against_ground_truth(extracted_data)
        
        if is_perfect_match:
            print("ğŸ‰ SUCCESS: Perfect match with ground truth!")
            print("âœ… All financial statement sections extracted correctly")
            
            output_file = 'extracted_financial_data.json'
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(extracted_data, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ Results saved to: {output_file}")
            
            return True
        else:
            print("âŒ FAILED: Output does not match ground truth")
            extractor.compare_and_report_differences(extracted_data)
            
            output_file = 'extracted_financial_data_failed.json'
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(extracted_data, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ Failed results saved to: {output_file}")
            
            return False
            
    except Exception as e:
        print(f"âŒ EXTRACTION FAILED: {e}")
        return False


if __name__ == '__main__':
    success = main()
    exit(0 if success else 1)
